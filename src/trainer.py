# src/trainer.py (æœ€ç»ˆä¿®æ­£ç‰ˆï¼šå¥å£®ã€ä¸¥è°¨ã€ç¬¦åˆå­¦æœ¯è§„èŒƒ)

import torch
import torch.nn as nn
from torch.optim import AdamW
from torch.utils.data import DataLoader, Dataset
from tqdm.auto import tqdm 
from sklearn.metrics import f1_score, recall_score, accuracy_score 
import pandas as pd
import time
import copy 
from utils.collate import collate_epc 
import numpy as np

# --- ä»å…¶ä»–æ¨¡å—å¯¼å…¥å¿…è¦çš„ç»„ä»¶ ---
from model import GatedMultimodalEPC, TextOnlyModel, SpeechOnlyModel, StaticFusionModel, BaseWavLMModel 
# å‡è®¾ features.py ä¸­çš„ get_dummy_features ç°åœ¨è¿”å› F_t, F_s_e2v, F_s_wavlm (ä¸‰ä¸ª)
from features import get_dummy_features, get_dummy_labels, TEXT_DIM, SPEECH_DIM 
from dataset import IEMOCAPDataset 


# --- å ä½ç¬¦ï¼šè™šæ‹Ÿæ•°æ®é›† (ç”¨äºæœ¬åœ°æµ‹è¯•) ---
class DummyConversationDataset(Dataset):
    # ... (åˆå§‹åŒ–å’Œ __len__ ä¿æŒä¸å˜) ...
    def __init__(self, num_samples, history_len, num_classes):
        self.num_samples = num_samples
        self.history_len = history_len
        self.num_classes = num_classes
        
    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        # ğŸš¨ ä¿®æ­£ï¼šä» features å¯¼å…¥çš„ get_dummy_features ç°åœ¨è¿”å› F_t, F_s_e2v, F_s_wavlm (ä¸‰ä¸ª)
        F_t, F_s_e2v, F_s_wavlm = get_dummy_features(batch_size=1, sequence_length=self.history_len)
        labels = get_dummy_labels(batch_size=1, num_classes=self.num_classes)
        
        # é»˜è®¤ä½¿ç”¨ F_s_e2v ä½œä¸ºé€šç”¨ F_s è¿›è¡Œæµ‹è¯•
        return {
            'F_t': F_t.squeeze(0),
            'F_s': F_s_e2v.squeeze(0), 
            'target_label': labels.squeeze(0), 
            'mask': torch.ones(self.history_len, dtype=torch.bool)
        }


class Trainer:
    # ... (__init__ ä¿æŒä¸å˜) ...
    def __init__(self, model, learning_rate, weight_decay, num_classes, patience=10):
        self.model = model
        self.criterion = nn.CrossEntropyLoss() 
        self.optimizer = AdamW(
            self.model.parameters(), 
            lr=learning_rate, 
            weight_decay=weight_decay
        )
        self.num_classes = num_classes
        self.patience = patience 
        
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
        # print(f"Trainer initialized. Using device: {self.device}") # ç®€åŒ–è¾“å‡º

    def train_epoch(self, dataloader, epoch_idx):
        self.model.train()
        total_loss = 0
        all_preds = []
        all_labels = []

        desc = f"Epoch {epoch_idx + 1:02d} | Train"
        for batch in tqdm(dataloader, desc=desc, disable=True): 
            # ... (è®­ç»ƒé€»è¾‘ä¿æŒä¸å˜) ...
            F_t = batch['F_t'].to(self.device)
            F_s = batch['F_s'].to(self.device)
            labels = batch['target_label'].to(self.device)

            self.optimizer.zero_grad()

            # --- å‰å‘ä¼ æ’­ ---
            model_output = self.model(F_t, F_s)

            # --- åŒºåˆ†æ˜¯å¦æœ‰ gate è¾“å‡º ---
            if isinstance(model_output, tuple):
                logits, W_gate = model_output
            else:
                logits = model_output
                W_gate = None

            # --- æ ‡ç­¾ç»´åº¦è°ƒæ•´ ---
            if labels.dim() > 1:
                labels = labels.squeeze(-1)

            # --- åŸºç¡€äº¤å‰ç†µæŸå¤± ---
            loss = self.criterion(logits, labels)

            # --- âœ…ã€æ–°å¢ã€‘Gate Balance Regularization ---
            # ä»…å¯¹ GatedMultimodalEPC æ¨¡å‹å¯ç”¨
            if W_gate is not None and isinstance(self.model, GatedMultimodalEPC):
                lambda_balance = 5e-4   # å¯è°ƒï¼Œå»ºè®®ä» 1e-3 å¼€å§‹
                loss_balance = torch.mean((W_gate - 0.5) ** 2)
                loss = loss + lambda_balance * loss_balance

            # --- åå‘ä¼ æ’­ ---
            loss.backward()
            self.optimizer.step()


            total_loss += loss.item() * F_t.size(0)
            
            preds = torch.argmax(logits, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            
        avg_loss = total_loss / len(dataloader.dataset)
        macro_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)
        
        return avg_loss, macro_f1


    def evaluate(self, dataloader, desc="Evaluation"):
        self.model.eval() 
        total_loss = 0
        all_preds = []
        all_labels = []
        all_gate_weights = [] 

        with torch.no_grad():
            for batch in tqdm(dataloader, desc=desc, disable=True): 
                F_t = batch['F_t'].to(self.device)
                F_s = batch['F_s'].to(self.device)
                labels = batch['target_label'].to(self.device)
                
                if labels.dim() > 1:
                    labels = labels.squeeze(-1)

                model_output = self.model(F_t, F_s)
                
                if isinstance(model_output, tuple): 
                    logits = model_output[0]
                    gate_weights = model_output[1] 
                    
                    # æ”¶é›†æœ€åä¸€ä¸ªå›åˆçš„å¹³å‡æƒé‡
                    # avg_gate_per_sample = gate_weights[:, -1, :].mean(dim=-1).cpu().numpy()
                    # all_gate_weights.extend(avg_gate_per_sample)
                    # âœ… è®¡ç®—æ¯ä¸ªæ ·æœ¬åœ¨æ—¶é—´ç»´ä¸Šçš„å¹³å‡ gateï¼ˆæ¯ä¸€è½®è¯çš„æ•´ä½“åå¥½ï¼‰
                    gate_mean_per_sample = gate_weights.mean(dim=(1, 2)).cpu().numpy()  # å¹³å‡å€¼

                    # âœ… è®¡ç®—æ¯ä¸ªæ ·æœ¬å†…éƒ¨ï¼ˆæ—¶é—´ç»´ï¼‰çš„æ ‡å‡†å·®ï¼Œè¡¨ç¤ºåŠ¨æ€å˜åŒ–ç¨‹åº¦
                    gate_std_per_sample = gate_weights.std(dim=1).mean(dim=1).cpu().numpy()  # å¹³å‡æ³¢åŠ¨å¹…åº¦

                    # âœ… ä¿å­˜ä¸¤ç§ç»Ÿè®¡é‡
                    all_gate_weights.append({
                        "mean": gate_mean_per_sample,
                        "std": gate_std_per_sample
                    })

                else:
                    logits = model_output 
                
                loss = self.criterion(logits, labels)
                total_loss += loss.item() * F_t.size(0)
                
                preds = torch.argmax(logits, dim=1)
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

        avg_loss = total_loss / len(dataloader.dataset)
        macro_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)
        uar = recall_score(all_labels, all_preds, average='macro', zero_division=0)
        wa = accuracy_score(all_labels, all_preds)   # âœ… æ–°å¢ Weighted Accuracy
        
        return avg_loss, macro_f1, uar, wa, all_labels, all_preds, all_gate_weights  # âœ… å¤šè¿”å›ä¸€ä¸ª WA


# --- å¤–éƒ¨è¿è¡Œå‡½æ•° (run_cross_validation) ---


def run_cross_validation(ModelClass, config):
    
   
    if 'original_data_root' not in config:
        config['original_data_root'] = config.get('data_root', '/path/to/iemocap') # é€‚é…æœ¬åœ°æµ‹è¯•
    
    # æ ¹æ®æ¨¡å‹ç±»å‹ç¡®å®šä½¿ç”¨çš„è¯­éŸ³ç‰¹å¾ tag
    model_name = ModelClass.__name__
    if model_name in ['GatedMultimodalEPC', 'SpeechOnlyModel', 'StaticFusionModel', 'TextOnlyModel']:
        tag = 'e2v' 
    elif model_name == 'BaseWavLMModel':
        tag = 'wavlm'
    else:
        raise ValueError(f"Unknown Model Class {model_name} for tag determination.")


    sessions = [f'Session{i}' for i in range(1, 6)] 
    

    # åˆå§‹åŒ–ç»“æœ DataFrame
    results_df = pd.DataFrame(columns=['Session', 'Test_Loss', 'Test_Macro_F1', 'Test_UAR', 'Test_WA', 'Train_Time_s', 'Best_Epoch'])
    all_test_f1s = []
    
    # åˆå§‹åŒ–å…¨å±€æ•°æ®æ”¶é›†åˆ—è¡¨
    global_labels = []
    global_preds = []
    global_gate_weights = []
    
    print(f"\n--- Starting 5-Fold Cross-Validation for {ModelClass.__name__} (Feature: {tag}) ---")

    for fold_idx, target_session in enumerate(sessions):
        start_time = time.time()
        
        print(f"\n=======================================================")
        print(f"| FOLD {fold_idx + 1}/5: Test on {target_session} |")
        print(f"=======================================================")
        

        # --- 1. æ•°æ®åŠ è½½ (ä¼ å…¥ tag) ---
        
        train_dataset = IEMOCAPDataset(
            config['original_data_root'], 
            target_session, 
            is_train=True, 
            history_len=config['history_len'], 
            feature_cache_path=config['feature_cache_path'],
            speech_feature_tag=tag 
        )
        test_dataset = IEMOCAPDataset(
            config['original_data_root'], 
            target_session, 
            is_train=False, 
            history_len=config['history_len'], 
            feature_cache_path=config['feature_cache_path'],
            speech_feature_tag=tag 
        )

        # ğŸš¨ æ›¿æ¢ï¼šä½¿ç”¨è™šæ‹Ÿæ•°æ®åŠ è½½å™¨è¿›è¡Œæœ¬åœ°æµ‹è¯•ï¼ˆå¦‚æœéœ€è¦ï¼‰
        # train_dataset = DummyConversationDataset(config['test_samples'] * 4, config['history_len'], config['num_classes'])
        # test_dataset = DummyConversationDataset(config['test_samples'], config['history_len'], config['num_classes'])

        train_dataloader = DataLoader(
            train_dataset, 
            batch_size=config['batch_size'], 
            shuffle=True,
            collate_fn=collate_epc  # <-- ä¿®æ­£ï¼šè®­ç»ƒé›†ä½¿ç”¨è‡ªå®šä¹‰ collate_fn
        )
        
        test_dataloader = DataLoader(
            test_dataset, 
            batch_size=config['batch_size'], 
            shuffle=False,
            collate_fn=collate_epc   # <-- ä¿®æ­£ï¼šæµ‹è¯•é›†ä½¿ç”¨è‡ªå®šä¹‰ collate_fn
        )

        # --- 2. åˆå§‹åŒ–æ¨¡å‹å’Œ Trainer ---
        model_instance = ModelClass(
            text_dim=TEXT_DIM, 
            speech_dim=SPEECH_DIM, 
            hidden_size=config['hidden_size'], 
            num_classes=config['num_classes']
        )
        
        
        trainer = Trainer(
            model=model_instance, 
            learning_rate=config['learning_rate'], 
            weight_decay=config['weight_decay'], 
            num_classes=config['num_classes'],
            patience=config['patience'] 
        )
        
        
        # æ¯æ¬¡å¼€å§‹è®­ç»ƒå‰ï¼Œé‡ç½®ä¼˜åŒ–å™¨çŠ¶æ€
        trainer.optimizer = AdamW(
            trainer.model.parameters(), 
            lr=config['learning_rate'], 
            weight_decay=config['weight_decay']
        )

        best_f1 = -1.0
        epochs_no_improve = 0
        best_model_state = None
        best_epoch = 0
        best_loss = 0.0
        best_uar = 0.0
        test_labels_at_best = []
        test_preds_at_best = []
        test_gates_at_best = []


        # --- 3. è®­ç»ƒå¾ªç¯ (å¸¦æ—©åœ) ---
        for epoch in range(config['epochs']):
            train_loss, train_f1 = trainer.train_epoch(train_dataloader, epoch)
                    
            test_loss, test_f1, test_uar, test_wa, test_labels, test_preds, test_gates = trainer.evaluate(test_dataloader, desc="Test/Validation")  

            print(f"[Epoch {epoch+1:02d}] | TrainLoss={train_loss:.2f} | TestLoss={test_loss:.2f} | F1={test_f1:.2f} | UAR={test_uar:.2f} | WA={test_wa:.2f}")

            # --- 4. æ—©åœå’Œæ¨¡å‹ä¿å­˜ (åŸºäº UAR) ---
            if test_uar > best_uar:
                best_uar = test_uar
                best_f1 = test_f1
                best_loss = test_loss
                best_wa = test_wa          # âœ… æ–°å¢ï¼šä¿å­˜æœ€ä½³ WA
                best_model_state = copy.deepcopy(model_instance.state_dict())
                epochs_no_improve = 0
                best_epoch = epoch + 1
                
                # æ”¶é›†æœ€ä½³ UAR æ—¶çš„åŸå§‹æ•°æ®
                test_labels_at_best = test_labels
                test_preds_at_best = test_preds
                test_gates_at_best = test_gates
            else:
                epochs_no_improve += 1
            
            if epochs_no_improve >= config['patience']:
                print(f"Early stopping triggered after {best_epoch} epochs (patience={config['patience']}).")
                break
        
        # --- 5. è®°å½•æœ€ç»ˆç»“æœ ---
        train_duration = time.time() - start_time # ğŸš¨ ä¿®æ­£ 4ï¼šè®°å½•å½“å‰ fold çš„æ€»è€—æ—¶
        
        all_test_f1s.append(best_f1)
        
        # å°†æ•°æ®æ·»åŠ åˆ°å…¨å±€åˆ—è¡¨ (ç”¨äºæ±‡æ€»æ‰€æœ‰ Fold çš„æ•°æ®)
        global_labels.extend(test_labels_at_best)
        global_preds.extend(test_preds_at_best)
        global_gate_weights.extend(test_gates_at_best)

        # å°†ç»“æœæ·»åŠ åˆ° DataFrame
        new_row = pd.Series({
            'Session': target_session,
            'Test_Loss': best_loss, 
            'Test_Macro_F1': best_f1,
            'Test_UAR': best_uar, 
            'Test_WA': best_wa,     # âœ… æ”¹è¿™é‡Œï¼Œå†™ best_wa è€Œä¸æ˜¯ test_wa
            'Train_Time_s': train_duration,
            'Best_Epoch': best_epoch
        })



        results_df.loc[len(results_df)] = new_row
            
    print("\n=======================================================")
    print(f"| Cross-Validation FINISHED for {ModelClass.__name__} |")
    print("=======================================================")
    
    avg_f1 = results_df['Test_Macro_F1'].mean()
    std_f1 = results_df['Test_Macro_F1'].std()
    
    print(f"Average Macro F1: {avg_f1:.4f} (+/- {std_f1:.4f})")

    results_df = results_df.round(2)
    # === ä¿å­˜ Gate åŠ¨æ€æ€§æ•°æ® ===
    if len(global_gate_weights) > 0:
        gate_means = np.concatenate([x["mean"] for x in global_gate_weights])
        gate_stds = np.concatenate([x["std"] for x in global_gate_weights])
        
        np.savez(
            f"./gate_stats_{ModelClass.__name__}.npz",
            gate_means=gate_means,
            gate_stds=gate_stds
        )
        print(f"âœ… Gate dynamics saved to gate_stats_{ModelClass.__name__}.npz")

        
    # è¿”å›ç»“æœ DataFrame å’ŒåŸå§‹æ•°æ® (ä¾› Cell 7 ç”¨äºå›¾è¡¨ç”Ÿæˆ)
    return results_df, global_labels, global_preds, global_gate_weights


def run_experiment(config):
    # ... (ModelClass æ˜ å°„ä¿æŒä¸å˜) ...
    model_map = {
        "GM-EPC": GatedMultimodalEPC,
        "Text-Only": TextOnlyModel,
        "Speech-Only": SpeechOnlyModel,
        "Static-Fusion": StaticFusionModel,
        "Dynamic-WavLM": BaseWavLMModel 
    }
    
    if config['model_name'] not in model_map:
        raise ValueError(f"Unknown model name: {config['model_name']}. Choose from {list(model_map.keys())}")
        
    ModelClass = model_map[config['model_name']]
    
    final_results = run_cross_validation(ModelClass, config) 
    
    return final_results

# ====================================================================
# æœ¬åœ°æµ‹è¯•ä»£ç å— (if __name__ == '__main__':)
# ====================================================================
if __name__ == '__main__':
    print("--- Starting Local Code Logic Test (Full CV Simulation) ---")

    # --- 1. å®éªŒé…ç½® (ä»£æ›¿ YAML æ–‡ä»¶) ---
    CONFIG = {
        'model_name': 'GM-EPC', # æµ‹è¯• Gated Multimodal EPC
        'data_root': '/path/to/iemocap', 
        'history_len': 3,
        'num_classes': 4,
        'batch_size': 8,
        'epochs': 10,
        'learning_rate': 1e-4,
        'weight_decay': 1e-5,
        'hidden_size': 64,
        'test_samples': 20, 
        'patience': 3,
        'feature_cache_path': './GM-EPC/data/features_cache', 
        # æ³¨æ„ï¼šä½ éœ€è¦ç¡®ä¿ run_cross_validation ä½¿ç”¨çš„æ˜¯ 'data_root' ä½œä¸ºåŸå§‹è·¯å¾„
    }
    
    # ä¿®æ­£ run_cross_validation ä¸­çš„è·¯å¾„æ˜ å°„ (ç¡®ä¿ä½¿ç”¨ data_root)
    CONFIG['original_data_root'] = CONFIG['data_root']
    
    # --- 2. è¿è¡Œå®Œæ•´çš„è™šæ‹Ÿå®éªŒ ---
    try:
        results_df = run_experiment(CONFIG)
        
        print("\n--- Full CV Simulation Successful ---")
        print("Aggregated Results:")
        print(results_df)
        print(f"\nOverall Mean F1: {results_df['Test_Macro_F1'].mean():.4f} (+/- {results_df['Test_Macro_F1'].std():.4f})")
        print("Training logic and CV loop verified. You are ready for real data!")
        
    except Exception as e:
        print("\n--- Test FAILED ---")
        print(f"An error occurred during the CV loop: {e}")
        # æ‰“å°è¯¦ç»† traceback
        import traceback
        traceback.print_exc()
