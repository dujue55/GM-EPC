# src/model.py (ä¼˜åŒ–ç‰ˆ)

import torch
import torch.nn as nn
import torch.nn.functional as F


# --- æ ¸å¿ƒæ¨¡å‹ (Model 5: GM-EPC) ---

class GatedMultimodalEPC(nn.Module):
    """
    Gated Multimodal Emotion Prediction in Conversation (GM-EPC) æ¨¡å‹ã€‚
    ä½¿ç”¨çº¿æ€§å±‚å¯¹é½ç‰¹å¾ç»´åº¦ï¼Œç„¶åè¿›è¡ŒåŠ¨æ€é—¨æ§èåˆã€‚
    """
    def __init__(self, text_dim, speech_dim, hidden_size, num_classes):
        super(GatedMultimodalEPC, self).__init__()
        
        # 1. ç»´åº¦å¯¹é½å±‚ï¼šåªæœ‰åœ¨ç»´åº¦ä¸åŒ¹é…æ—¶æ‰ä½¿ç”¨æŠ•å½±å±‚ (å¢å¼ºé²æ£’æ€§)
        self.use_projection = (speech_dim != text_dim)
        if self.use_projection:
            self.speech_projection = nn.Linear(speech_dim, text_dim)
        
        # ç»´åº¦å¯¹é½åçš„ç‰¹å¾ç»´åº¦
        aligned_dim = text_dim
        
        # 2. Gating Unitï¼šè¾“å…¥æ˜¯æ‹¼æ¥åçš„ç‰¹å¾ (2 * aligned_dim)ï¼Œè¾“å‡ºæ˜¯é—¨æ§æƒé‡ (aligned_dim)
        self.gate_linear = nn.Linear(2 * aligned_dim, aligned_dim) 
        self.sigmoid = nn.Sigmoid()
        
        # 3. GRU å±‚ï¼šè¾“å…¥ç»´åº¦æ˜¯èåˆåçš„ç‰¹å¾ç»´åº¦ (aligned_dim)
        self.gru = nn.GRU(
            input_size=aligned_dim, 
            hidden_size=hidden_size, 
            num_layers=1, 
            batch_first=True
        )
        
        # 4. åˆ†ç±»å±‚ï¼šç§»é™¤æœ€åä¸€å±‚çš„ ReLU/Dropoutï¼Œç¡®ä¿è¾“å‡ºæ˜¯ logits
        self.classifier = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(0.3), # ä¼˜åŒ–ï¼šå°† Dropout ç§»åˆ° ReLU ä¹‹å
            nn.Linear(hidden_size // 2, num_classes) # æœ€åä¸€å±‚æ˜¯ Logitsï¼Œæ— æ¿€æ´»å‡½æ•°
        )
    
    def forward(self, F_t, F_s):
        # F_t: [B, L, D_t], F_s: [B, L, D_s]
        
        # 1. ç»´åº¦å¯¹é½
        F_s_aligned = self.speech_projection(F_s) if self.use_projection else F_s
        
        # 2. æ‹¼æ¥ (H_t)
        H_t_concat = torch.cat((F_t, F_s_aligned), dim=-1)
        
        # 3. è®¡ç®—é—¨æ§æƒé‡ (W_gate)
        W_gate = self.sigmoid(self.gate_linear(H_t_concat))
        
        # 4. åŠ¨æ€èåˆ (F_fused = W_gate âŠ™ F_t + (1 - W_gate) âŠ™ F_s_aligned)
        F_fused = W_gate * F_t + (1 - W_gate) * F_s_aligned
        
        # 5. GRU ç¼–ç 
        gru_out, _ = self.gru(F_fused)
        
        # 6. é¢„æµ‹ï¼šåªå–æœ€åä¸€ä¸ªå›åˆçš„è¾“å‡º
        final_output = gru_out[:, -1, :]
        
        # 7. åˆ†ç±»
        logits = self.classifier(final_output)
        
        return logits, W_gate


# --- åŸºçº¿æ¨¡å‹ 1: çº¯æ–‡æœ¬ (Text-only) ---

class TextOnlyModel(nn.Module):
    def __init__(self, text_dim, speech_dim, hidden_size, num_classes):
        super(TextOnlyModel, self).__init__()
        self.gru = nn.GRU(text_dim, hidden_size, batch_first=True)
        self.classifier = nn.Linear(hidden_size, num_classes)
        
    def forward(self, F_t, F_s): 
        gru_out, _ = self.gru(F_t)
        return self.classifier(gru_out[:, -1, :])


# --- åŸºçº¿æ¨¡å‹ 2: çº¯è¯­éŸ³ (Speech-only) ---

class SpeechOnlyModel(nn.Module):
    def __init__(self, text_dim, speech_dim, hidden_size, num_classes):
        super(SpeechOnlyModel, self).__init__()
        # ä¿®æ­£ï¼šå¦‚æœ D_s != D_tï¼Œæˆ‘ä»¬ä»ç„¶éœ€è¦å¤„ç† D_s çš„è¾“å…¥ç»´åº¦
        self.gru = nn.GRU(speech_dim, hidden_size, batch_first=True)
        self.classifier = nn.Linear(hidden_size, num_classes)
        
    def forward(self, F_t, F_s): 
        gru_out, _ = self.gru(F_s)
        return self.classifier(gru_out[:, -1, :])


# --- åŸºçº¿æ¨¡å‹ 3: é™æ€èåˆ (Static Fusion) ---

class StaticFusionModel(nn.Module):
    def __init__(self, text_dim, speech_dim, hidden_size, num_classes):
        super(StaticFusionModel, self).__init__()
        
        # 1. å¯¹é½å±‚
        self.use_projection = (speech_dim != text_dim)
        if self.use_projection:
            self.speech_projection = nn.Linear(speech_dim, text_dim)
        
        aligned_dim = text_dim
        input_size = text_dim + aligned_dim # èåˆåçš„ç»´åº¦
        
        # 2. GRU
        self.gru = nn.GRU(
            input_size=input_size, 
            hidden_size=hidden_size, 
            num_layers=1, 
            batch_first=True
        )
        
        # 3. åˆ†ç±»å±‚ (ä¸ GM-EPC ç›¸åŒ)
        self.classifier = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(0.3), # ä¼˜åŒ–ï¼šå°† Dropout ç§»åˆ° ReLU ä¹‹å
            nn.Linear(hidden_size // 2, num_classes)
        )

    def forward(self, F_t, F_s):
        # 1. ç»´åº¦å¯¹é½
        F_s_aligned = self.speech_projection(F_s) if self.use_projection else F_s
        
        # 2. é™æ€æ‹¼æ¥èåˆ
        F_static_fused = torch.cat((F_t, F_s_aligned), dim=-1)
        
        # 3. GRU ç¼–ç 
        gru_out, _ = self.gru(F_static_fused)
        
        # 4. åˆ†ç±»
        return self.classifier(gru_out[:, -1, :])


# --- åŸºçº¿æ¨¡å‹ 4: Dynamic WavLM (å ä½ç¬¦) ---
# è¿™ä¸ªç±»åœ¨è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ GatedMultimodalEPCï¼Œä½†ä¼ å…¥ WavLM çš„ç‰¹å¾ã€‚
# å› æ­¤ï¼Œè¿™ä¸ªå ä½ç¬¦ç±»æ˜¯ç”¨äºç»“æ„å®Œæ•´æ€§çš„ã€‚
class BaseWavLMModel(TextOnlyModel): # ç»§æ‰¿TextOnlyModelä»¥ä¿æŒç®€å•ï¼Œå®é™…é€»è¾‘åœ¨trainerä¸­å¤„ç†ç‰¹å¾åŠ è½½
    pass


# ====================================================================
# æœ¬åœ°æµ‹è¯•ä»£ç å— (if __name__ == '__main__':)
# ====================================================================
if __name__ == '__main__':
    # ç¡®ä¿æ‚¨çš„ features.py ä¸­çš„æ–‡ä»¶è·¯å¾„æ­£ç¡®
    try:
        from features import get_dummy_features, TEXT_DIM, SPEECH_DIM
    except ImportError:
        from .features import get_dummy_features, TEXT_DIM, SPEECH_DIM

    print("--- Testing All Model Architectures ---")
    
    # è®¾å®šæµ‹è¯•å‚æ•°
    # è®¾å®šæµ‹è¯•å‚æ•°
    BATCH_SIZE = 8
    HISTORY_LEN = 3 
    GRU_HIDDEN_SIZE = 256
    NUM_CLASSES = 4
    
    # ğŸš¨ ä¿®æ­£ï¼šTEXT_DIM å’Œ SPEECH_DIM åº”ä» features.py å¯¼å…¥ï¼Œæ— éœ€é‡æ–°å®šä¹‰
    # å‡è®¾ features.py ä¸­çš„ TEXT_DIM=768, SPEECH_DIM=768 (æˆ‘ä»¬ä¹‹å‰ç»Ÿä¸€äº†ç»´åº¦)
    
    # ğŸš¨ ä¿®æ­£ï¼šè°ƒç”¨ get_dummy_features æ—¶åªä¼ å…¥ä¸¤ä¸ªå‚æ•°ï¼Œå¹¶æ¥æ”¶ä¸‰ä¸ªè¿”å›
    dummy_input_t, dummy_input_s_e2v, dummy_input_s_wavlm = get_dummy_features(BATCH_SIZE, HISTORY_LEN)
    
    # ä¸ºäº†æµ‹è¯•å•æ¨¡æ€å’Œèåˆï¼Œæˆ‘ä»¬ç»Ÿä¸€ä½¿ç”¨ F_s_e2v ä½œä¸ºè¯­éŸ³è¾“å…¥ F_s
    dummy_input_s = dummy_input_s_e2v
    
    models_to_test = {
        "GM-EPC (Core)": GatedMultimodalEPC,
        "Text Only (Baseline 1)": TextOnlyModel,
        "Speech Only (Baseline 2)": SpeechOnlyModel,
        "Static Fusion (Baseline 3)": StaticFusionModel,
        "Dynamic WavLM (Baseline 4)": BaseWavLMModel,
    }

    for name, ModelClass in models_to_test.items():
        print(f"\nTesting {name}...")
        try:
            model = ModelClass(
                # ğŸš¨ ä¿®æ­£ï¼šä½¿ç”¨å¯¼å…¥çš„å¸¸é‡ä½œä¸ºç»´åº¦
                text_dim=TEXT_DIM, 
                speech_dim=SPEECH_DIM, 
                hidden_size=GRU_HIDDEN_SIZE, 
                num_classes=NUM_CLASSES
            )
            output = model(dummy_input_t, dummy_input_s)
            
            if name == "GM-EPC (Core)":
                logits, W_gate = output  # ğŸ‘ˆ è§£åŒ…ä¸¤ä¸ªè¿”å›å€¼
                final_output = logits
                
                # éªŒè¯é—¨æ§æƒé‡å½¢çŠ¶ (å¯é€‰ï¼Œä½†æ¨è)
                assert W_gate.shape == (BATCH_SIZE, HISTORY_LEN, TEXT_DIM)
            else:
                final_output = output  # ğŸ‘ˆ å…¶ä»–æ¨¡å‹åªè¿”å› logits
            
            # ä½¿ç”¨ final_output éªŒè¯æœ€ç»ˆçš„åˆ†ç±»å™¨å½¢çŠ¶
            assert final_output.shape == (BATCH_SIZE, NUM_CLASSES)

            print(f"  SUCCESS: Output shape {output.shape} verified.")
            
        except Exception as e:
            print(f"  FAILED: Error during test for {name}: {e}")