# src/dataset.py

import torch
from torch.utils.data import Dataset
import os
import re # ç”¨äºæ­£åˆ™è¡¨è¾¾å¼è§£ææ–‡ä»¶

# å®šä¹‰æƒ…ç»ªæ ‡ç­¾åˆ° ID çš„æ˜ å°„ï¼ˆå¦‚Happy/Excited, Angry, Sad, Neutralï¼‰
EMO_MAP = {
    'hap': 0, 'exc': 0,  # ç»Ÿä¸€åˆ° Happy/Excited (ID 0)
    'ang': 1,            # Angry (ID 1)
    'sad': 2,            # Sad (ID 2)
    'neu': 3,            # Neutral (ID 3)
}
# è¿‡æ»¤æ‰ä¸éœ€è¦çš„æƒ…ç»ªï¼Œå¦‚ frustration, surprise, disgust, other, unknown, XXX
TARGET_EMOS = list(EMO_MAP.keys())


class IEMOCAPDataset(Dataset):
    """
    å¤„ç† IEMOCAP æ•°æ®é›†ï¼Œå¹¶å°†å…¶æ ¼å¼åŒ–ä¸º EPC ä»»åŠ¡çš„è¾“å…¥ã€‚
    """
    
    def __init__(self, data_root, target_session, is_train=True, history_len=3):
        """
        åˆå§‹åŒ–æ•°æ®é›†ã€‚
        :param data_root: IEMOCAP åŸå§‹æ–‡ä»¶çš„æ ¹ç›®å½•è·¯å¾„ï¼Œä¾‹å¦‚ 'IEMOCAP_full_release'ã€‚
        :param target_session: å½“å‰è¦ä½œä¸ºæµ‹è¯•é›†çš„ Session å· (e.g., 'Session5')ã€‚
        :param is_train: æ˜¯å¦åŠ è½½è®­ç»ƒé›† (True) æˆ–æµ‹è¯•é›† (False)ã€‚
        :param history_len: æ¨¡å‹çš„ä¸Šä¸‹æ–‡é•¿åº¦ Lã€‚
        """
        self.data_root = data_root
        self.history_len = history_len
        
        # é¢„åŠ è½½æ‰€æœ‰ Session çš„æ•°æ®
        self.raw_utterances_by_session = {}
        for i in range(1, 6):
            session_name = f"Session{i}"
            self.raw_utterances_by_session[session_name] = self._collect_session_utterances(session_name)

        # åŸºäº LOO-CV è§„åˆ™åˆ‡åˆ†æ ·æœ¬
        self.samples = self._load_and_split_data(target_session, is_train)
        print(f"Loaded {'Train' if is_train else 'Test'} samples: {len(self.samples)} for target session {target_session}")

    def _load_and_split_data(self, target_session, is_train):
        """
        åŠ è½½ IEMOCAP åŸå§‹æ•°æ®ï¼Œæ ¹æ®äº¤å‰éªŒè¯è§„åˆ™åˆ‡åˆ†ï¼Œå¹¶æ ¼å¼åŒ–ä¸º [å†å²å›åˆ, ç›®æ ‡æƒ…ç»ª] çš„æ ·æœ¬ã€‚
        """
        all_samples = []
        
        # ç¡®å®šéœ€è¦å¤„ç†çš„ Sessions
        sessions_all = [f"Session{i}" for i in range(1, 6)]
        
        if is_train:
            # è®­ç»ƒé›†ï¼šé™¤äº† target_session ä¹‹å¤–çš„æ‰€æœ‰ Sessions
            data_sessions = [s for s in sessions_all if s != target_session]
        else:
            # æµ‹è¯•é›†ï¼šåªæœ‰ target_session
            data_sessions = [target_session]
        
        print(f"Processing sessions: {data_sessions}")

        for session in data_sessions:
            # --- æ­¥éª¤ 1: è·å–å½“å‰ Session å†…çš„æ‰€æœ‰å›åˆï¼ˆå·²åœ¨ __init__ ä¸­é¢„åŠ è½½ï¼‰ ---
            utterances = self.raw_utterances_by_session[session]
            
            if not utterances:
                continue

            # --- æ­¥éª¤ 2: è½¬æ¢æˆ EPC ä»»åŠ¡æ ·æœ¬ ---
            # utterances æ˜¯ä¸€ä¸ªæŒ‰æ—¶é—´é¡ºåºæ’åˆ—çš„åˆ—è¡¨: [u_1, u_2, ..., u_N]
            
            for i in range(len(utterances)):
                # æˆ‘ä»¬é¢„æµ‹å›åˆ i+1 çš„æƒ…ç»ª
                if i + 1 < len(utterances):
                    
                    target_utterance = utterances[i + 1]
                    target_emo_str = target_utterance['label']
                    
                    # ç¡®ä¿ç›®æ ‡æƒ…ç»ªæ˜¯è¦é¢„æµ‹çš„å››ç±»ä¹‹ä¸€
                    if target_emo_str in TARGET_EMOS:
                        
                        # å†å²å›åˆï¼š[u_{i-L+1}, ..., u_i]
                        history_start_index = max(0, i - self.history_len + 1)
                        history = utterances[history_start_index : i + 1]
                        
                        target_label_id = EMO_MAP[target_emo_str]
                        
                        # æ„é€ æœ€ç»ˆæ ·æœ¬
                        sample = {
                            # å†å²å›åˆçš„æ–‡æœ¬å’ŒéŸ³é¢‘è·¯å¾„
                            'history_texts': [u['text'] for u in history],
                            'history_audio_paths': [u['audio_path'] for u in history],
                            # ç›®æ ‡æƒ…ç»ªæ ‡ç­¾ (ID)
                            'target_label': target_label_id,
                            # ç›®æ ‡å›åˆçš„æ–‡æœ¬å’ŒéŸ³é¢‘è·¯å¾„ (ç”¨äºç‰¹å¾æå–å™¨ä¸­çš„ç‰¹å¾å¯¹é½å’Œ padding)
                            'target_text': target_utterance['text'], 
                            'target_audio_path': target_utterance['audio_path'] 
                        }
                        all_samples.append(sample)

        return all_samples

    # src/dataset.py (æ›¿æ¢æ•´ä¸ª _collect_session_utterances å‡½æ•°)

    def _collect_session_utterances(self, session):
        """
        è§£æ IEMOCAP åŸå§‹æ–‡ä»¶ï¼Œæ”¶é›†ä¸€ä¸ª Session å†…æ‰€æœ‰å›åˆçš„æ–‡æœ¬ã€æ ‡ç­¾å’ŒéŸ³é¢‘è·¯å¾„ã€‚
        """
        
        
        # 1. æ‰¾åˆ°è¯¥ Session ä¸‹çš„æ‰€æœ‰å¯¹è¯ç›®å½• (Impro/Script)
        session_dir = os.path.join(self.data_root, session, 'dialog', 'transcriptions')
        
        # --- è°ƒè¯•ç‚¹ Aï¼šç¡®è®¤è½¬å½•æ–‡ä»¶å¤¹è·¯å¾„å’Œå­˜åœ¨æ€§ ---
        print(f"DEBUG A [{session}]: Checking Transcription Dir: {session_dir}") 
        
        if not os.path.exists(session_dir):
            # è¯·ç¡®ä¿ self.data_root æ˜¯ç»å¯¹æ­£ç¡®çš„è·¯å¾„ï¼
            print(f"ERROR: Transcription directory not found: {session_dir}. Check data_root path.")
            return [] # å¦‚æœè·¯å¾„ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºåˆ—è¡¨

        # 2. éå†è½¬å½•æ–‡ä»¶ä»¥è·å– Utterance ID, æ–‡æœ¬å’Œæ—¶é—´é¡ºåº
        dialog_trans_files = [f for f in os.listdir(session_dir) if f.endswith('.txt')]

        # --- è°ƒè¯•ç‚¹ Bï¼šç¡®è®¤æ‰¾åˆ°è½¬å½•æ–‡ä»¶æ•°é‡ ---
        print(f"DEBUG B [{session}]: Found {len(dialog_trans_files)} transcription files.")
        
        # ç”¨äºå­˜å‚¨å¯¹è¯å›åˆï¼Œé”®æ˜¯ Utterance ID (e.g., Ses01F_impro01_F000)
        dialog_data = {} 

        # ã€ä¿®æ­£è½¬å½•æ­£åˆ™ã€‘ ä½¿ç”¨ä¸€ä¸ªå‡†ç¡®ä¸”åŒ…å«æ‰€æœ‰å››ä¸ªæ•è·ç»„çš„æ­£åˆ™ã€‚
        # åŒ¹é…ï¼š[ 0.0000 - 0.9999 ] Ses01F_impro01_F000: HEY!
        trans_regex_full = re.compile(r'\[\s*([\d\.]+)\s*-\s*([\d\.]+)\s*\]\s*(\w+)\s*:\s*(.*)', re.S)


        for trans_file_name in dialog_trans_files:
            trans_path = os.path.join(session_dir, trans_file_name)
            
            try:
                with open(trans_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                # å°è¯• latin-1
                with open(trans_path, 'r', encoding='latin-1') as f:
                    content = f.read()
                
            # æ‰¾åˆ°æ‰€æœ‰åŒ¹é…çš„å›åˆ - åŒ¹é…å››ä¸ªæ•è·ç»„
            matches = trans_regex_full.findall(content)
            
            # ğŸš¨ ä¿®æ­£ï¼šå¾ªç¯æ—¶å¿…é¡»è§£åŒ…å››ä¸ªå€¼
            for start_time, end_time, utt_id, text_raw in matches:
                # è§„èŒƒåŒ–æ–‡æœ¬ï¼Œç§»é™¤é¦–å°¾ç©ºç™½å’Œå¤šä½™çš„æ¢è¡Œ
                text = text_raw.strip().replace('\n', ' ')
                
                # é¢„å…ˆå­˜å‚¨è½¬å½•ä¿¡æ¯
                dialog_data[utt_id] = {
                    'text': text,
                    # å­˜å‚¨æ—¶é—´
                    'start': float(start_time), 
                    'end': float(end_time),
                }

        # --- è°ƒè¯•ç‚¹ Cï¼šç¡®è®¤æ­£åˆ™åŒ¹é…æˆåŠŸè§£æåˆ°æ•°æ® ---
        print(f"DEBUG C [{session}]: Successfully parsed {len(dialog_data)} utterances from transcriptions.")

        # 3. éå†æƒ…ç»ªæ ‡æ³¨æ–‡ä»¶æ¥æ·»åŠ æƒ…ç»ªæ ‡ç­¾å’Œæ—¶é—´é¡ºåº
        emotion_dir = os.path.join(self.data_root, session, 'dialog', 'EmoEvaluation')
        
        if not os.path.exists(emotion_dir):
            print(f"ERROR: Emotion directory not found: {emotion_dir}.")
            return [] # å¦‚æœæƒ…ç»ªæ ‡æ³¨æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œè¿”å›ç©º
            
        dialog_emo_files = [f for f in os.listdir(emotion_dir) if f.endswith('.txt')]
        
        # æ­£åˆ™è¡¨è¾¾å¼ç”¨äºè§£ææƒ…ç»ªæ ‡æ³¨æ–‡ä»¶
        # åŒ¹é…: [ 0.0000 - 0.9999 ] - Ses01F_impro01_F000 [neu]
        # ä¿®æ­£ï¼šä½¿ç”¨æ›´å®‰å…¨çš„æ­£åˆ™æ•è· ID å’Œæ ‡ç­¾
        emo_regex = re.compile(r'\[.+?\]\s*-\s*(\w+)\s*\[(\w+)\]', re.IGNORECASE | re.DOTALL)


        final_utterance_list = [] # æœ€ç»ˆæŒ‰æ—¶é—´é¡ºåºæ’åˆ—çš„å›åˆåˆ—è¡¨

        for emo_file_name in dialog_emo_files:
            emo_path = os.path.join(emotion_dir, emo_file_name)
            
            try:
                with open(emo_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                with open(emo_path, 'r', encoding='latin-1') as f:
                    content = f.read()
                
            # æ‰¾åˆ°æ‰€æœ‰æƒ…ç»ªæ ‡æ³¨åŒ¹é…é¡¹
            matches = emo_regex.findall(content)
            
            for utt_id, label in matches:
                label = label.lower()
                
                # æ£€æŸ¥æ˜¯å¦åœ¨æˆ‘ä»¬å·²ç»è§£æçš„è½¬å½•æ–‡æœ¬ä¸­
                if utt_id in dialog_data:
                    # è·å–è¯¥å›åˆçš„è¯¦ç»†ä¿¡æ¯
                    data = dialog_data[utt_id]
                    
                    # æ„é€ éŸ³é¢‘æ–‡ä»¶è·¯å¾„
                    dialog_name = "_".join(utt_id.split('_')[:-1])
                    
                    audio_sub_path = os.path.join(
                        session, 'sentences', 'wav', dialog_name, f'{utt_id}.wav'
                    )
                    full_audio_path = os.path.join(self.data_root, audio_sub_path)
                    
                    # å¦‚æœæƒ…ç»ªä¸åœ¨ TARGET_EMOS å†…ï¼Œæˆ‘ä»¬å¿½ç•¥è¿™ä¸ªå›åˆ
                    # æ‚¨çš„åŸå§‹ä»£ç é€»è¾‘æ˜¯æ”¶é›†æ‰€æœ‰ï¼Œç„¶ååœ¨ _load_and_split_data ä¸­è¿‡æ»¤ï¼Œè¿™é‡Œä¿æŒåŸæ ·
                    if label in TARGET_EMOS or label in ['fru', 'sur', 'dis', 'oth', 'xxx']:
                        final_utterance_list.append({
                            'utt_id': utt_id,
                            'text': data['text'],
                            'audio_path': full_audio_path,
                            'label': label,
                            'start': data['start'],
                            'end': data['end']
                        })


        # 4. æŒ‰ utt_id æ’åºç¡®ä¿é¡ºåºæ­£ç¡®
        final_utterance_list.sort(key=lambda x: x['utt_id'])
        
        # --- è°ƒè¯•ç‚¹ Dï¼šç¡®è®¤æœ€ç»ˆåˆå¹¶/è¿‡æ»¤åçš„æ•°æ®é‡ ---
        print(f"DEBUG D [{session}]: Final utterance list size: {len(final_utterance_list)}")
        
        return final_utterance_list

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        # è¿”å›æ–‡æœ¬å’ŒéŸ³é¢‘è·¯å¾„ï¼ˆä»¥åŠæ ‡ç­¾ï¼‰ï¼Œç‰¹å¾æå–åœ¨å¦ä¸€ä¸ªæ–‡ä»¶/é˜¶æ®µå¤„ç†
        return {
            'history_texts': sample['history_texts'],
            'history_audio_paths': sample['history_audio_paths'],
            # è¿”å›ç›®æ ‡å›åˆä¿¡æ¯ï¼Œè¿™å¯¹äºç‰¹å¾æå–å™¨åœ¨å¤„ç†æœ€åçš„ L ä¸ªå›åˆæ—¶å¾ˆé‡è¦
            'target_text': sample['target_text'],
            'target_audio_path': sample['target_audio_path'],
            'target_label': sample['target_label']
        }

# ====================================================================
# æœ¬åœ°è°ƒè¯•ä»£ç  (IEMOCAP æ•°æ®ä¸‹è½½å®Œæˆåï¼Œå†è¿è¡Œ)
# ====================================================================
if __name__ == '__main__':
    print("--- Testing IEMOCAP Dataset Initialization (Requires actual data structure) ---")
    
    # ï¼ï¼ï¼ è¿è¡Œå‰ï¼Œè¯·è®¾ç½® IEMOCAP_ROOT ï¼ï¼ï¼
    # å‡è®¾æ‚¨çš„ IEMOCAP æ ¹ç›®å½•è·¯å¾„
    # ä¾‹å¦‚ï¼š
    # IEMOCAP_ROOT = 'data/IEMOCAP_raw/IEMOCAP_full_release' 
    IEMOCAP_ROOT = 'YOUR_IEMOCAP_ROOT_PATH' 

    # è­¦å‘Šï¼šæ­¤æµ‹è¯•ä»…åœ¨æ‚¨ä¸‹è½½äº†åŸå§‹ IEMOCAP æ–‡ä»¶å¹¶å°†å…¶æ”¾åœ¨æ­£ç¡®çš„ä½ç½®æ—¶æ‰èƒ½è¿è¡Œï¼

    # åˆ›å»ºä¸€ä¸ªè®­ç»ƒé›† (Leave Session5 out)
    try:
        train_dataset = IEMOCAPDataset(IEMOCAP_ROOT, target_session='Session5', is_train=True, history_len=3)
        print(f"Train Dataset Size: {len(train_dataset)}")

        # åˆ›å»ºä¸€ä¸ªæµ‹è¯•é›† (ä»… Session5)
        test_dataset = IEMOCAPDataset(IEMOCAP_ROOT, target_session='Session5', is_train=False, history_len=3)
        print(f"Test Dataset Size: {len(test_dataset)}")
        
        # æ‰“å°ä¸€ä¸ªæ ·æœ¬è¿›è¡Œæ£€æŸ¥
        if len(train_dataset) > 0:
            sample = train_dataset[0]
            print("\n--- Sample 0 ---")
            print(f"History Texts ({len(sample['history_texts'])}): {sample['history_texts']}")
            print(f"Target Text: {sample['target_text']}")
            print(f"Target Label ID: {sample['target_label']}")
            print(f"Audio Path Example: {sample['history_audio_paths'][0]}")

    except Exception as e:
        print(f"\nFATAL ERROR: Dataset loading failed. Ensure IEMOCAP_ROOT is correct and files exist.")
        print(f"Details: {e}")